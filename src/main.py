# -*- coding: utf-8 -*-
"""Assignment-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ifA7xuZreRWyuy5etwEeiYNkL02T-hmC

## Assignment 1: Flight Delay Prediciton
```
- Machine Learning, Innopolis University (Fall semester 2021)
- Student: Ahmed Mohsen Mohamed Abdelkhalek ELsayed ALi
```

## Test for libraries installation
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import sklearn

import matplotlib.pyplot as plt
# %matplotlib inline

"""## Read Data with Pandas"""

data = pd.read_csv('./flight_delay.csv')
data.rename(columns = {'Scheduled depature time': 'Scheduled_depature_time', 'Scheduled arrival time': 'Scheduled_arrival_time','Depature Airport':'Depature_Airport','Destination Airport':'Destination_Airport'}
            , inplace = True) #Change columns names so that they can be accessed later

"""## Data exploration"""

print('Data Exploration:')
print(data.head())

types = data.dtypes
print("Number categorical featues:", sum(types=='object'))
print(types)

"""### **Features Engineering**"""

data['Scheduled_depature_time']  =pd.to_datetime(data.Scheduled_depature_time)#Converting from string to datetime
data['Scheduled_arrival_time']=pd.to_datetime(data.Scheduled_arrival_time)#Converting from string to datetime
data['flight_duration']=((data['Scheduled_arrival_time']-data['Scheduled_depature_time']).dt.total_seconds())/60 #Calculating fligth duration
data=data.drop('Scheduled_arrival_time',axis=1)

print('\nData with flight duration:')
print(data.head())

types = data.dtypes
print("Number categorical featues:", sum(types=='object'))
print(types)

"""### **Label Encoder**"""

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
cat_feats = ['Depature_Airport' , 'Destination_Airport']
new_data=data[cat_feats].apply(encoder.fit_transform)
data['Depature_Airport'],data['Destination_Airport'] = new_data['Depature_Airport'] ,new_data['Destination_Airport']

print('Label Encoder Result:')
print(data.head())

"""### **Data Splitting**"""

#Split the data by datetime
ts=pd.to_datetime('1/1/2018')
train_data=data.loc[data.Scheduled_depature_time< ts,:]
test_data=data.loc[data.Scheduled_depature_time >= ts,:]

#Drop Scheduled_depature_time feature as it will not be a predictor
train_data=train_data.drop('Scheduled_depature_time',axis=1)
test_data=test_data.drop('Scheduled_depature_time',axis=1)

#Reset the index and drop the old index
test_data=test_data.reset_index()
test_data=test_data.drop('index',axis=1)
train_data=train_data.reset_index()
train_data=train_data.drop('index',axis=1)

#Extracting x_train,y_train,x_test,y_test 
x_train,y_train = train_data.drop('Delay', axis=1),train_data['Delay']
x_test,y_test = test_data.drop('Delay', axis=1),test_data['Delay']

"""### **Features Scaling**

"""

from sklearn.preprocessing import  MinMaxScaler
scaler =  MinMaxScaler()
scaler.fit(x_train)
x_train=scaler.transform(x_train)
x_test=scaler.transform(x_test)

"""### **Visualizing The data**"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

# Plot Scaled Flight Duration vs Delay.
plt.scatter(x_train[:,2],y_train, label= 'Delay',marker='.')
plt.title('Scaled Flight Duration vs Delay')
plt.xlabel('Flight Duration')
plt.ylabel('Delay (in minutes)')
plt.legend(loc = 1)
plt.show()

# Plot Scaled Departure Airport vs Delay.
plt.scatter(x_train[:,0],y_train, label= 'Delay',marker='.')
plt.title('Scaled Departure Airport vs Delay')
plt.xlabel('Departure Airpor')
plt.ylabel('Delay (in minutes)')
plt.legend(loc = 1)
plt.show()


# Plot Scaled Destination Airport vs Delay.
plt.scatter(x_train[:,1],y_train, label= 'Delay',marker='.')
plt.title('Scaled Destination Airport vs Delay')
plt.xlabel('Destination Airpor')
plt.ylabel('Delay (in minutes)')
plt.legend(loc = 1)
plt.show()

"""# **Outlier Detection**"""

from sklearn.neighbors import LocalOutlierFactor
#x_train=x_train.values
lof = LocalOutlierFactor()
yhat = lof.fit_predict(x_train)

print("Before Outliers: ",x_train.shape, y_train.shape)
# select all rows that are not outliers
mask = yhat != -1
x_train, y_train = x_train[mask, :], y_train[mask]


# summarize the shape of the updated training dataset
print("After Outliers: ",x_train.shape, y_train.shape)

plt.scatter(x_train[:,2],y_train, label= 'Delay')
plt.title('Flight Duration vs Delay (without outliers)')
plt.xlabel('Flight Duration')
plt.ylabel('Delay (in minutes)')
#plt.xlim([0,1])
plt.legend(loc = 1)
plt.show()

plt.scatter(x_train[:,0],y_train, label= 'Delay',marker='.')
plt.title('Scaled Departure Airport vs Delay (without outliers)')
plt.xlabel('Departure Airpor')
plt.ylabel('Delay (in minutes)')
plt.legend(loc = 1)
plt.show()


# Plot Scaled Destination Airport vs Delay.
plt.scatter(x_train[:,1],y_train, label= 'Delay',marker='.')
plt.title('Scaled Destination Airport vs Delay (without outliers)')
plt.xlabel('Destination Airpor')
plt.ylabel('Delay (in minutes)')
plt.legend(loc = 1)
plt.show()

"""### **Linear Regression**"""

from sklearn.linear_model import LinearRegression
from sklearn import metrics


regressor = LinearRegression()
regressor.fit(x_train, y_train)
print(f"Model intercept : {regressor.intercept_}")
print(f"Model coefficient : {regressor.coef_}")

y_pred1 = regressor.predict(x_test)
yr_pred1 = regressor.predict(x_train)

print("\n\n\n\tLinear Regression Results")
print('Train Error: ')
print('Mean Absolute Error:', metrics.mean_absolute_error(y_train, yr_pred1))
print('Mean Squared Error:', metrics.mean_squared_error(y_train, yr_pred1))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, yr_pred1)))
print('Coefficient of Determination:', metrics.r2_score(y_train, yr_pred1))

print('\nTest Error: ')
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred1))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred1))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred1)))
print('Coefficient of Determination:', metrics.r2_score(y_test, y_pred1))

"""### **Polynomial Regression**"""

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures 
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
from sklearn import metrics

degrees = [2, 3, 4]


for i in range(len(degrees)):
    
    polynomial_features = PolynomialFeatures(degree=degrees[i])
    linear_regression = LinearRegression()
    pipeline = Pipeline([("polynomial_features", polynomial_features),
                         ("linear_regression", linear_regression)])
    pipeline.fit(x_train, y_train)

    # Evaluate the models using crossvalidation
    scores = cross_val_score(pipeline, x_train, y_train,
                             scoring="neg_mean_squared_error", cv=6)

    yr_pred1=pipeline.predict(x_train)
    y_pred1 = pipeline.predict(x_test)
    
    print('\n\n\n\t\t This is Polynomial Regression with ',degrees[i],'degree' )
    print('Train Error: ')
    print('Mean Absolute Error:', metrics.mean_absolute_error(y_train, yr_pred1))
    print('Mean Squared Error:', metrics.mean_squared_error(y_train, yr_pred1))
    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train, yr_pred1)))
    print('Coefficient of Determination:', metrics.r2_score(y_train, yr_pred1))
    print('\nTest Error: ')
    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred1))
    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred1))
    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred1)))
    print('Coefficient of Determination:', metrics.r2_score(y_test, y_pred1))

"""### **Lasso Regularizaiton**


"""

from sklearn.linear_model import Lasso

lasso = Lasso()
lasso.fit(x_train, y_train)
print("Lasso Coefficient", lasso.coef_)

# Commented out IPython magic to ensure Python compatibility.
from sklearn.metrics import mean_squared_error
# %matplotlib inline
alphas = [5, 2, 1.5, 1.3, 1.2, 1.1, 1, 0.3, 0.1]
losses = []
for alpha in alphas:
    lasso = Lasso(alpha=alpha)
    lasso.fit(x_train, y_train)
    y_pred3 = lasso.predict(x_test)
    mse = mean_squared_error(y_test, y_pred3)
    losses.append(mse)
plt.plot(alphas, losses)
plt.title("Lasso alpha value selection")
plt.xlabel("alpha")
plt.ylabel("Mean squared error")
plt.show()

best_alpha = alphas[np.argmin(losses)]
print("Best value of alpha:", best_alpha,np.argmin(losses))

from sklearn import metrics
lasso = Lasso(best_alpha)
lasso.fit(x_train, y_train)
y_lass=lasso.predict(x_train)

y_pred_lasso = lasso.predict(x_test)

print('\n\n\n\tLasso Regularization Results')
print('Train Error: ')
print('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y_lass))
print('Mean Squared Error:', metrics.mean_squared_error(y_train, y_lass))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train,y_lass)))
print('Coefficient of Determination:', metrics.r2_score(y_train, y_lass))

print('\nTest Error: ')
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test,y_pred_lasso))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_lasso))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test,y_pred_lasso)))
print('Coefficient of Determination:', metrics.r2_score(y_test, y_pred_lasso))

# Commented out IPython magic to ensure Python compatibility.
from sklearn.linear_model import Ridge


ridge = Ridge()
ridge.fit(x_train, y_train)

print("Lasso Coefficient", lasso.coef_)

from sklearn.metrics import mean_squared_error
# %matplotlib inline
alphas = [5, 2, 1.5, 1.3, 1.2, 1.1, 1, 0.3, 0.1]
losses1 = []
for alpha in alphas:
  
    ridge = Ridge(alpha=alpha)
    ridge.fit(x_train, y_train)
    y_pred4 = ridge.predict(x_test)
    mse = mean_squared_error(y_test, y_pred3)
    losses1.append(mse)
plt.plot(alphas, losses)
plt.title("Ridge alpha value selection")
plt.xlabel("alpha")
plt.ylabel("Mean squared error")
plt.show()

best_alpha = alphas[np.argmin(losses)]
print("Best value of alpha:", best_alpha,np.argmin(losses))

from sklearn import metrics
ridge = Ridge(best_alpha)
ridge.fit(x_train, y_train)
y_ridge=ridge.predict(x_train)

y_pred_ridge = ridge.predict(x_test)
print('\n\n\n\tRidge Regularization Results')
print('Train Error: ')
print('Mean Absolute Error:', metrics.mean_absolute_error(y_train, y_ridge))
print('Mean Squared Error:', metrics.mean_squared_error(y_train,y_ridge))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_train,y_ridge)))
print('Coefficient of Determination:', metrics.r2_score(y_train, y_ridge))

print('\nTest Error: ')
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test,y_pred_ridge))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred_ridge))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test,y_pred_ridge)))
print('Coefficient of Determination:', metrics.r2_score(y_test, y_pred_ridge))